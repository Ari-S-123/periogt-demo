# PerioGT HPC Backend

HPC deployment surface for PerioGT inference, sharing runtime code with the Modal backend in `services/modal-api/periogt_runtime`.

## What This Package Provides

- CLI entrypoint: `python -m periogt_hpc` (Click-based)
- Optional FastAPI server mode: `python -m periogt_hpc.server`
- Packaging assets for:
  - Slurm + Apptainer (primary)
  - Slurm + Conda (fallback)
- Filesystem artifact setup/indexing for cluster workflows

## Command Surface

```bash
python -m periogt_hpc predict
python -m periogt_hpc embeddings
python -m periogt_hpc batch
python -m periogt_hpc doctor
python -m periogt_hpc setup
```

## Runtime Requirements

- `DGLBACKEND=pytorch` must be set.
- `PERIOGT_RUNTIME_PACKAGE_DIR` (or `PYTHONPATH`) must make `periogt_runtime` importable.
- CUDA 12.6 environments require NVIDIA driver `>= 560.28`.
- Minimum GPU compute capability for CUDA mode is `7.0`.

Required artifacts under `PERIOGT_CHECKPOINT_DIR`:

- `pretrained_ckpt/`
- `finetuned_ckpt/`
- `label_stats.json`
- `descriptor_scaler.pkl`
- `index.json` (generated by `setup` or on first bootstrap path)

## Configuration

Resolved by `periogt_hpc.config.resolve_config`:

- `PERIOGT_BASE_DIR` (default `$HOME/periogt`)
- `PERIOGT_CHECKPOINT_DIR` (default `$PERIOGT_BASE_DIR/checkpoints`)
- `PERIOGT_RESULTS_DIR` (default `$PERIOGT_BASE_DIR/results`)
- `PERIOGT_SRC_DIR` (PerioGT_common source tree)
- `PERIOGT_DEVICE` (`auto`, `cpu`, `cuda`)
- `PERIOGT_RUNTIME_PACKAGE_DIR`
- `PERIOGT_HOST`, `PERIOGT_PORT` (server mode)
- `PERIOGT_API_KEY` (optional `X-Api-Key` auth in server mode)

## Quick Start (Conda Fallback)

```bash
bash services/hpc/conda/install.sh periogt
conda activate periogt

# verify environment, driver, GPU, and artifact readiness
python -m periogt_hpc doctor

# if artifacts are pre-staged:
python -m periogt_hpc setup --skip-download

# single prediction
python -m periogt_hpc predict --smiles "*CC*" --property tg --format json
```

## Batch Prediction Example

```bash
python -m periogt_hpc batch \
  --input /path/to/input.csv \
  --property eps \
  --output /path/to/results.csv
```

Output columns:

- `id`
- `smiles`
- `property`
- `prediction_value`
- `prediction_units`
- `ok`
- `error_code`
- `error_message`
- `request_id`

## Optional Server Mode

```bash
export PERIOGT_HOST=0.0.0.0
export PERIOGT_PORT=8000
# optional auth gate
export PERIOGT_API_KEY=secret-token

python -m periogt_hpc.server
```

Routes mirror Modal API shape under `/v1/*`:

- `GET /v1/health`
- `GET /v1/properties`
- `POST /v1/predict`
- `POST /v1/embeddings`
- `POST /v1/predict/batch`

## Error and Exit Semantics

Error taxonomy includes:

- `validation_error`
- `unsupported_property`
- `checkpoint_missing`
- `checksum_mismatch`
- `model_load_failed`
- `cuda_unavailable`
- `gpu_unsupported`
- `driver_incompatible`
- `internal_error`

CLI exit codes:

- `0` full success
- `1` partial batch failure (row-level failures present)
- `2` fatal configuration/setup/runtime failure

## Testing

```bash
pytest services/hpc/tests
bash scripts/hpc_cli_smoke_test.sh <PERIOGT_CHECKPOINT_DIR>
pwsh scripts/hpc_cli_smoke_test.ps1 <PERIOGT_CHECKPOINT_DIR>
```

## Notes from Reviewed HPC Spec

Implemented details from `periogt-hpc-backend-feature-spec-reviewed.md` include:

- `setup` subcommand and `--skip-download` flow.
- Atomic `index.json` writes for safer concurrent setup behavior.
- Apptainer `runtime` base image direction and explicit bind-mount guidance.
- Conda two-step installation for PyTorch/DGL wheels.
- Cluster guardrails for Explorer `/scratch` volatility and driver checks.
